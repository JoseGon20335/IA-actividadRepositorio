{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTELIGENCIA ARTIFICIAL \n",
    "## = LABORATORIO 4 =\n",
    "\n",
    "Jose Miguel Gonzalez\n",
    "20335"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1.1\n",
    "Leer el fichero CSV proporcionado y almacenarlo en un np.array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv(\"framingham.csv\")\n",
    "\n",
    "# Remove the rows with missing values\n",
    "data = data.dropna()\n",
    "data = pd.DataFrame(data)\n",
    "data = data.drop(columns=['education'])\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Select the independent variables (features)\n",
    "X = data[[\"age\", \"cigsPerDay\", \"prevalentHyp\", \"sysBP\", \"BMI\"]].values\n",
    "# Select the dependent variable (target)\n",
    "y = data[\"TenYearCHD\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1.2\n",
    "Ajuste un modelo logístico polinómico basado en el conjunto de datos cargado en la matriz que relacione las variables independientes que considere apropiadas (puede no utilizar todos los componentes de X, con\n",
    "variables independientes que considere oportunas (puede no utilizar todos los componentes de X), con la variable de salida dependiente (sufre o no de\n",
    "variable de salida dependiente (sufre o no una parada cardiaca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Replace NaN values with median values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_std = imputer.fit_transform(X_train_std)\n",
    "X_test_std = imputer.transform(X_test_std)\n",
    "\n",
    "# Fit a polynomial logistic regression model using the training data\n",
    "model = Pipeline([\n",
    "(\"poly\", PolynomialFeatures(degree=2)),\n",
    "(\"logreg\", LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train_std, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1.3\n",
    "Use la implementación vectorial del algoritmo de regresión logística (descenso gradiente visto en clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regresionLogica:\n",
    "\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "\n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            self.theta -= self.lr * gradient\n",
    "\n",
    "            if self.verbose and i % 10000 == 0:\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.sigmoid(z)\n",
    "                print(f'Loss: {self.loss(h, y)}')\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "\n",
    "        return self.sigmoid(np.dot(X, self.theta))\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train a logistic regression model using gradient descent algorithm\n",
    "lr = regresionLogica(lr=0.1, num_iter=100000)\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict the output using the trained model\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = (y_pred == y).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1.4\n",
    "Mediante validación cruzada, determine el grado del polinomio que mejor describa la nube de puntos (encuentre el mejor equilibrio entre la adhesión a los datos de entrenamiento y el grado del polinomio).\n",
    "equilibrio entre la adherencia a los datos de entrenamiento y la generalización a datos no observados previamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "model = Pipeline([\n",
    "(\"poly\", PolynomialFeatures()),\n",
    "(\"logreg\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameters to search over\n",
    "params = {\n",
    "\"poly__degree\": [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "grid = GridSearchCV(model, params, cv=5)\n",
    "grid.fit(X_train_std, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best degree:\", grid.best_params_[\"poly__degree\"])\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1.5\n",
    "Realice un análisis de sus resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
